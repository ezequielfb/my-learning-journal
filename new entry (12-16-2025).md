# Entry: First ML Model - Linear Regression
**Date:** 16/dez/2025

## Concept Learned: Linear Regression
I learned that Linear Regression tries to find the "best fitting line" through data points. It minimizes the distance (error) between the real points and the line.

## AI Collaboration
- **Challenge:** I wasn't sure how to visualize the regression line on top of the scatter plot.
- **AI Solution:** The AI suggested using `np.linspace` to create a range of ages to plot a smooth red line.
- **My Understanding:** The code `modelo.fit(X_train, y_train)` is where the "magic" happensâ€”the math calculates the slope and intercept automatically.

## Critical Analysis (Self-Reflection)
I noticed that my dataset is very small (only 5 people).
- **Risk:** With only 1 person in the "Test Set", the accuracy metric (MAE) is not statistically reliable.
- **Lesson:** Machine Learning needs **data**. For the next project, I need a CSV with at least 50-100 rows to see real results.

## Technical Deep Dive: The `.reshape(-1, 1)` Mystery
While visualizing the regression line, I used a numpy trick that I didn't fully understand at first.

### The Problem
`np.linspace` creates a flat array (1D), like a simple list of numbers. However, Scikit-Learn models follow Linear Algebra rules and expect a **Matrix (2D)** as input (Rows x Columns), even if there is only one feature (column).

### The Solution
```python
.reshape(-1, 1)
